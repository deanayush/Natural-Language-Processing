{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import string\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.metrics.distance  import edit_distance\n",
    "from nltk.corpus import words\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "from spellchecker import SpellChecker\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from autocorrect import Speller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1129,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('A1_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>DATE_TIME</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Fri Jun 05 14:26:50 2009</td>\n",
       "      <td>About to get threaded and scared</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Thu May 14 10:13:55 2009</td>\n",
       "      <td>@awaisnaseer I like Shezan Mangooo too!!! I ha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LABEL                 DATE_TIME  \\\n",
       "0      0  Fri Jun 05 14:26:50 2009   \n",
       "1      1  Thu May 14 10:13:55 2009   \n",
       "\n",
       "                                                TEXT  \n",
       "0                  About to get threaded and scared   \n",
       "1  @awaisnaseer I like Shezan Mangooo too!!! I ha...  "
      ]
     },
     "execution_count": 1130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1131,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new = data[['LABEL', 'TEXT']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>About to get threaded and scared</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@awaisnaseer I like Shezan Mangooo too!!! I ha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LABEL                                               TEXT\n",
       "0      0                  About to get threaded and scared \n",
       "1      1  @awaisnaseer I like Shezan Mangooo too!!! I ha..."
      ]
     },
     "execution_count": 1132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(data):\n",
    "    data_new['TEXT'] = data_new['TEXT'].apply(word_tokenize) \n",
    "    return data_new['TEXT']\n",
    "\n",
    "def lower(data):\n",
    "    data_new['TEXT'] = data_new['TEXT'].astype(str).str.lower()\n",
    "    return data_new['TEXT']\n",
    "\n",
    "def remove_punctuations(data):\n",
    "    for punctuation in string.punctuation:\n",
    "        data = data.replace(punctuation, ' ')\n",
    "    return data\n",
    "\n",
    "def remove_punctuation_tokens(data):\n",
    "    data_new['TEXT'] = data_new['TEXT'].apply(remove_punctuations)\n",
    "    return data_new['TEXT']\n",
    "\n",
    "\n",
    "def remove_stopwords(data):\n",
    "    stop = list(stopwords.words(\"english\"))\n",
    "    data_new['TEXT'] = data_new['TEXT'].apply(lambda x: ' '.join([w for w in x.split() if w not in stop]))\n",
    "    return data_new['TEXT']\n",
    "\n",
    "def remove_URL(data):\n",
    "    return re.sub(r'http\\S+','', data)\n",
    "\n",
    "def remove_URL_data(data):\n",
    "    data_new['TEXT'] = data_new['TEXT'].apply(remove_URL)\n",
    "    return data_new['TEXT']\n",
    "\n",
    "def remove_HTMLTag(data):\n",
    "    return re.sub(r'&\\w+;',' ', data)\n",
    "\n",
    "def remove_HTMLTag_data(data):\n",
    "    data_new['TEXT'] = data_new['TEXT'].apply(remove_HTMLTag)\n",
    "    return data_new['TEXT']\n",
    "\n",
    "def lemmatize(data):\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        lemmatize = [lemmatizer.lemmatize(x) for x in data]\n",
    "        return lemmatize\n",
    "\n",
    "def lemmatize_data(data):\n",
    "    data_new['TEXT'] = data_new['TEXT'].apply(lemmatize)\n",
    "    return data_new['TEXT']\n",
    "\n",
    "def stemming(data):\n",
    "        # Porter stemmer\n",
    "        ps = PorterStemmer()\n",
    "        stem = [ps.stem(x) for x in data]\n",
    "        return stem\n",
    "    \n",
    "def stemming_data(data):\n",
    "    data_new['TEXT'] = data_new['TEXT'].apply(stemming)\n",
    "    return data_new['TEXT']\n",
    "\n",
    "def remove_username_func(data):\n",
    "    return re.sub(r'\\@\\w+|\\#|\\d+', '', data)\n",
    "\n",
    "def remove_username(data):\n",
    "    data_new['TEXT'] = data_new['TEXT'].apply(remove_username_func)\n",
    "    return data_new['TEXT']\n",
    "\n",
    "def remove_words_func(data):\n",
    "    return re.sub(r'\\b\\w{1,3}\\b', '', data)\n",
    "\n",
    "def remove_words(data):\n",
    "    data_new['TEXT'] = data_new['TEXT'].apply(remove_words_func)\n",
    "    return data_new['TEXT']\n",
    "\n",
    "def remove_repeated_words(data):\n",
    "    data_new['TEXT'] = data_new['TEXT'].str.replace(r'\\b(\\w+)(\\s+\\1)+\\b', r'\\1')\n",
    "    return data_new['TEXT']\n",
    "\n",
    "def remove_white_spaces(data):\n",
    "    data_new['TEXT'] = data_new['TEXT'].apply(lambda x: x.strip())\n",
    "    return data_new['TEXT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spell_correction(data):\n",
    "    spell = Speller()\n",
    "    data_new['TEXT'] = [' '.join([spell(i) for i in x.split()]) for x in data_new['TEXT']]\n",
    "    return data_new['TEXT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "       # x = a(data)\n",
    "       # print(x)\n",
    "        t = remove_URL_data(data)\n",
    "        #print(t5)\n",
    "        t2 = remove_HTMLTag_data(t)\n",
    "        #print(t5)\n",
    "        t3 = remove_username((t2))\n",
    "        #print(t3)\n",
    "        x = spell_correction(str(t3))\n",
    "        #print(x)\n",
    "        t4 = tokenize(str(t3))\n",
    "        #print(t)\n",
    "        t5 = lemmatize_data(t4)\n",
    "        #print(t4)   \n",
    "        t6 = stemming_data(t5)\n",
    "       # print(t5)   \n",
    "        t7 = lower(t5)\n",
    "        #print(t5)  \n",
    "      \n",
    "        t8 = remove_punctuation_tokens(t7)\n",
    "      #  print(t6)   \n",
    "        t9 = remove_stopwords(t8)\n",
    "      #  print(t9)      \n",
    "        t10 = remove_words(t9)\n",
    "      #  print(t10)\n",
    "        t11 = remove_repeated_words(t10)\n",
    "       # print(t11)\n",
    "        t12 = remove_white_spaces(t11)\n",
    "        print(t12)\n",
    "      #  print(type(t10))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                            thread scare\n",
      "1                              like sean mango  yesterday\n",
      "2       work show   sooooooooooo tire sparrow sign cowboy\n",
      "3       actual start  afternoon  someth  slow process ...\n",
      "4                            worry  vote  stop  love much\n",
      "                              ...                        \n",
      "4282                                  perform  test shock\n",
      "4283                        true blood episod demand onli\n",
      "4284                 return forest sarah merci lost  wood\n",
      "4285                          proud   piec work keep papa\n",
      "4286    woke    pizza breakfast also dentist appoint  ...\n",
      "Name: TEXT, Length: 4287, dtype: object\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>thread scare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>like sean mango  yesterday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>work show   sooooooooooo tire sparrow sign cowboy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>actual start  afternoon  someth  slow process ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>worry  vote  stop  love much</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LABEL                                               TEXT\n",
       "0      0                                       thread scare\n",
       "1      1                         like sean mango  yesterday\n",
       "2      1  work show   sooooooooooo tire sparrow sign cowboy\n",
       "3      1  actual start  afternoon  someth  slow process ...\n",
       "4      1                       worry  vote  stop  love much"
      ]
     },
     "execution_count": 1139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing the data in csv file for further use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1140,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.to_csv('A1_datset_processed.csv',encoding='utf-8-sig', index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
